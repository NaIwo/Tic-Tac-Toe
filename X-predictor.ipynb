{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dataset\\data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(PATH):\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    if ext == '.csv':\n",
    "        raw_dataset = pd.read_csv(PATH + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True\n",
       "5  x  x  x  x  o  o  b  b  o   True\n",
       "6  x  x  x  x  o  b  o  o  b   True\n",
       "7  x  x  x  x  o  b  o  b  o   True\n",
       "8  x  x  x  x  o  b  b  o  o   True\n",
       "9  x  x  x  x  b  o  o  o  b   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "raw_dataset.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(dataset):\n",
    "    size = dataset.shape[0]\n",
    "    dataset = dataset[np.random.permutation(size)]\n",
    "    board_x = np.where(dataset[:,:-1] == 'x', 1, np.where(dataset[:,:-1] == 'b', 0, -1))\n",
    "    target_x = np.where(dataset[:,-1:], 1, 0)\n",
    "    return np.concatenate((board_x, target_x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1  1  1 -1  1 -1  0  1  1]\n",
      " [ 1  0 -1  1  0 -1  1  0  0  1]\n",
      " [-1  1 -1  1  1  1  0  0 -1  1]\n",
      " [-1 -1  0  1  1  1  0  1 -1  1]\n",
      " [-1 -1  1  0 -1  1  0  1  1  1]\n",
      " [ 1  1  1 -1  0  0 -1 -1  1  1]\n",
      " [-1  0  1  0  1  0  1  0 -1  1]\n",
      " [ 0  0  1 -1  0  1  0 -1  1  1]\n",
      " [ 0 -1  1  1 -1  1  1 -1 -1  0]\n",
      " [ 1  0 -1 -1 -1  1 -1  1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "dataset = clean(np.array(raw_dataset))\n",
    "print(dataset[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = dataset.shape[0]\n",
    "x_train = (dataset[:size * 75 // 100, :-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_train = dataset[:size * 75 // 100, -1:]\n",
    "x_valid = (dataset[size * 75 // 100:size * 93 // 100, :-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_valid = dataset[size * 75 // 100:size * 93 // 100, -1:]\n",
    "x_test = (dataset[size * 93 // 100:,:-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_test = dataset[size * 93 // 100:, -1:]\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.  1.  ... 0.  0.5 1. ]\n",
      " [1.  0.5 0.  ... 1.  0.5 0.5]\n",
      " [0.  1.  0.  ... 0.5 0.5 0. ]\n",
      " ...\n",
      " [0.  0.  1.  ... 1.  0.  1. ]\n",
      " [0.  1.  0.  ... 1.  0.  1. ]\n",
      " [0.5 0.  0.5 ... 1.  1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "kl_divergence = keras.losses.kullback_leibler_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, weight, target = 0.1):\n",
    "        self.weight = weight\n",
    "        self.target = target\n",
    "    def  __call__(self, inputs):\n",
    "        mean_activities = K.mean(inputs, axis = 0)\n",
    "        return self.weight * (\n",
    "             kl_divergence(self.target, mean_activities) +\n",
    "             kl_divergence(1. - self.target, 1. - mean_activities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_reg = KLDRegularizer(weight = 0.05, target = 0.1)\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(450, activation = 'elu', input_shape = [9], kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(300, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(150, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(36, activation = 'sigmoid',activity_regularizer=kld_reg, kernel_initializer = 'he_normal')\n",
    "    #keras.layers.ActivityRegularization(l1=1e-3)\n",
    "])\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(150, activation = 'elu', input_shape = [36],  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(300, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(450, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(9, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_49 (Sequential)   (None, 36)                190386    \n",
      "_________________________________________________________________\n",
      "sequential_50 (Sequential)   (None, 9)                 190359    \n",
      "=================================================================\n",
      "Total params: 380,745\n",
      "Trainable params: 380,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', \n",
    "                    optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.92, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 172 samples\n",
      "Epoch 1/120\n",
      "668/668 [==============================] - 2s 2ms/sample - loss: 0.3970 - val_loss: 0.3443\n",
      "Epoch 2/120\n",
      "668/668 [==============================] - 0s 275us/sample - loss: 0.3624 - val_loss: 0.3268\n",
      "Epoch 3/120\n",
      "668/668 [==============================] - 0s 257us/sample - loss: 0.3538 - val_loss: 0.3233\n",
      "Epoch 4/120\n",
      "668/668 [==============================] - 0s 270us/sample - loss: 0.3473 - val_loss: 0.3239\n",
      "Epoch 5/120\n",
      "668/668 [==============================] - 0s 267us/sample - loss: 0.3433 - val_loss: 0.3207\n",
      "Epoch 6/120\n",
      "668/668 [==============================] - 0s 264us/sample - loss: 0.3432 - val_loss: 0.3198\n",
      "Epoch 7/120\n",
      "668/668 [==============================] - 0s 263us/sample - loss: 0.3373 - val_loss: 0.3171\n",
      "Epoch 8/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3361 - val_loss: 0.3161\n",
      "Epoch 9/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3344 - val_loss: 0.3149\n",
      "Epoch 10/120\n",
      "668/668 [==============================] - 0s 250us/sample - loss: 0.3345 - val_loss: 0.3171\n",
      "Epoch 11/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3351 - val_loss: 0.3138\n",
      "Epoch 12/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3312 - val_loss: 0.3141\n",
      "Epoch 13/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.3308 - val_loss: 0.3136\n",
      "Epoch 14/120\n",
      "668/668 [==============================] - 0s 256us/sample - loss: 0.3291 - val_loss: 0.3103\n",
      "Epoch 15/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.3283 - val_loss: 0.3093\n",
      "Epoch 16/120\n",
      "668/668 [==============================] - 0s 240us/sample - loss: 0.3279 - val_loss: 0.3126\n",
      "Epoch 17/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.3260 - val_loss: 0.3110\n",
      "Epoch 18/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.3249 - val_loss: 0.3091\n",
      "Epoch 19/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.3240 - val_loss: 0.3080\n",
      "Epoch 20/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3228 - val_loss: 0.3097\n",
      "Epoch 21/120\n",
      "668/668 [==============================] - 0s 257us/sample - loss: 0.3233 - val_loss: 0.3070\n",
      "Epoch 22/120\n",
      "668/668 [==============================] - 0s 245us/sample - loss: 0.3235 - val_loss: 0.3063\n",
      "Epoch 23/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.3222 - val_loss: 0.3068\n",
      "Epoch 24/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.3218 - val_loss: 0.3058\n",
      "Epoch 25/120\n",
      "668/668 [==============================] - 0s 247us/sample - loss: 0.3199 - val_loss: 0.3069\n",
      "Epoch 26/120\n",
      "668/668 [==============================] - 0s 263us/sample - loss: 0.3197 - val_loss: 0.3052\n",
      "Epoch 27/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3196 - val_loss: 0.3062\n",
      "Epoch 28/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3187 - val_loss: 0.3029\n",
      "Epoch 29/120\n",
      "668/668 [==============================] - 0s 259us/sample - loss: 0.3171 - val_loss: 0.3042\n",
      "Epoch 30/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.3179 - val_loss: 0.3039\n",
      "Epoch 31/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3159 - val_loss: 0.3031\n",
      "Epoch 32/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3152 - val_loss: 0.3033\n",
      "Epoch 33/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3154 - val_loss: 0.3041\n",
      "Epoch 34/120\n",
      "668/668 [==============================] - 0s 247us/sample - loss: 0.3152 - val_loss: 0.3012\n",
      "Epoch 35/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3136 - val_loss: 0.3007\n",
      "Epoch 36/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.3128 - val_loss: 0.3009\n",
      "Epoch 37/120\n",
      "668/668 [==============================] - 0s 259us/sample - loss: 0.3122 - val_loss: 0.3002\n",
      "Epoch 38/120\n",
      "668/668 [==============================] - 0s 273us/sample - loss: 0.3125 - val_loss: 0.3005\n",
      "Epoch 39/120\n",
      "668/668 [==============================] - 0s 261us/sample - loss: 0.3117 - val_loss: 0.3003\n",
      "Epoch 40/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.3106 - val_loss: 0.2998\n",
      "Epoch 41/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.3102 - val_loss: 0.2993\n",
      "Epoch 42/120\n",
      "668/668 [==============================] - 0s 255us/sample - loss: 0.3090 - val_loss: 0.2986\n",
      "Epoch 43/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3089 - val_loss: 0.2990\n",
      "Epoch 44/120\n",
      "668/668 [==============================] - 0s 227us/sample - loss: 0.3085 - val_loss: 0.3000\n",
      "Epoch 45/120\n",
      "668/668 [==============================] - 0s 269us/sample - loss: 0.3094 - val_loss: 0.2987\n",
      "Epoch 46/120\n",
      "668/668 [==============================] - 0s 257us/sample - loss: 0.3077 - val_loss: 0.2975\n",
      "Epoch 47/120\n",
      "668/668 [==============================] - 0s 243us/sample - loss: 0.3077 - val_loss: 0.2966\n",
      "Epoch 48/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3066 - val_loss: 0.2968\n",
      "Epoch 49/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.3070 - val_loss: 0.2967\n",
      "Epoch 50/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3055 - val_loss: 0.2969\n",
      "Epoch 51/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.3055 - val_loss: 0.2960\n",
      "Epoch 52/120\n",
      "668/668 [==============================] - 0s 250us/sample - loss: 0.3047 - val_loss: 0.2960\n",
      "Epoch 53/120\n",
      "668/668 [==============================] - 0s 245us/sample - loss: 0.3042 - val_loss: 0.2961\n",
      "Epoch 54/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3042 - val_loss: 0.2953\n",
      "Epoch 55/120\n",
      "668/668 [==============================] - 0s 255us/sample - loss: 0.3033 - val_loss: 0.2958\n",
      "Epoch 56/120\n",
      "668/668 [==============================] - 0s 258us/sample - loss: 0.3039 - val_loss: 0.2955\n",
      "Epoch 57/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.3031 - val_loss: 0.2949\n",
      "Epoch 58/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.3030 - val_loss: 0.2951\n",
      "Epoch 59/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3027 - val_loss: 0.2941\n",
      "Epoch 60/120\n",
      "668/668 [==============================] - 0s 245us/sample - loss: 0.3029 - val_loss: 0.2949\n",
      "Epoch 61/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.3018 - val_loss: 0.2942\n",
      "Epoch 62/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3020 - val_loss: 0.2946\n",
      "Epoch 63/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.3011 - val_loss: 0.2942\n",
      "Epoch 64/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.3018 - val_loss: 0.2942\n",
      "Epoch 65/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.3008 - val_loss: 0.2941\n",
      "Epoch 66/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.3011 - val_loss: 0.2940\n",
      "Epoch 67/120\n",
      "668/668 [==============================] - 0s 258us/sample - loss: 0.3010 - val_loss: 0.2938\n",
      "Epoch 68/120\n",
      "668/668 [==============================] - 0s 247us/sample - loss: 0.3001 - val_loss: 0.2940\n",
      "Epoch 69/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.3003 - val_loss: 0.2940\n",
      "Epoch 70/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2996 - val_loss: 0.2934\n",
      "Epoch 71/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2994 - val_loss: 0.2938\n",
      "Epoch 72/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.2988 - val_loss: 0.2936\n",
      "Epoch 73/120\n",
      "668/668 [==============================] - 0s 255us/sample - loss: 0.2993 - val_loss: 0.2929\n",
      "Epoch 74/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.2989 - val_loss: 0.2935\n",
      "Epoch 75/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2995 - val_loss: 0.2933\n",
      "Epoch 76/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.2985 - val_loss: 0.2930\n",
      "Epoch 77/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.2981 - val_loss: 0.2930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.2976 - val_loss: 0.2935\n",
      "Epoch 79/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.2979 - val_loss: 0.2930\n",
      "Epoch 80/120\n",
      "668/668 [==============================] - 0s 247us/sample - loss: 0.2982 - val_loss: 0.2933\n",
      "Epoch 81/120\n",
      "668/668 [==============================] - 0s 242us/sample - loss: 0.2970 - val_loss: 0.2926\n",
      "Epoch 82/120\n",
      "668/668 [==============================] - 0s 246us/sample - loss: 0.2974 - val_loss: 0.2926\n",
      "Epoch 83/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.2976 - val_loss: 0.2927\n",
      "Epoch 84/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.2967 - val_loss: 0.2930\n",
      "Epoch 85/120\n",
      "668/668 [==============================] - 0s 251us/sample - loss: 0.2969 - val_loss: 0.2925\n",
      "Epoch 86/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.2972 - val_loss: 0.2923\n",
      "Epoch 87/120\n",
      "668/668 [==============================] - 0s 245us/sample - loss: 0.2975 - val_loss: 0.2925\n",
      "Epoch 88/120\n",
      "668/668 [==============================] - 0s 257us/sample - loss: 0.2964 - val_loss: 0.2923\n",
      "Epoch 89/120\n",
      "668/668 [==============================] - 0s 258us/sample - loss: 0.2965 - val_loss: 0.2929\n",
      "Epoch 90/120\n",
      "668/668 [==============================] - 0s 259us/sample - loss: 0.2963 - val_loss: 0.2922\n",
      "Epoch 91/120\n",
      "668/668 [==============================] - 0s 255us/sample - loss: 0.2969 - val_loss: 0.2920\n",
      "Epoch 92/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2964 - val_loss: 0.2924\n",
      "Epoch 93/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.2964 - val_loss: 0.2919\n",
      "Epoch 94/120\n",
      "668/668 [==============================] - 0s 245us/sample - loss: 0.2962 - val_loss: 0.2924\n",
      "Epoch 95/120\n",
      "668/668 [==============================] - 0s 260us/sample - loss: 0.2963 - val_loss: 0.2924\n",
      "Epoch 96/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2961 - val_loss: 0.2926\n",
      "Epoch 97/120\n",
      "668/668 [==============================] - 0s 249us/sample - loss: 0.2956 - val_loss: 0.2921\n",
      "Epoch 98/120\n",
      "668/668 [==============================] - 0s 237us/sample - loss: 0.2960 - val_loss: 0.2927\n",
      "Epoch 99/120\n",
      "668/668 [==============================] - 0s 254us/sample - loss: 0.2960 - val_loss: 0.2926\n",
      "Epoch 100/120\n",
      "668/668 [==============================] - 0s 248us/sample - loss: 0.2959 - val_loss: 0.2931\n",
      "Epoch 101/120\n",
      "668/668 [==============================] - 0s 244us/sample - loss: 0.2958 - val_loss: 0.2920\n",
      "Epoch 102/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.2960 - val_loss: 0.2920\n",
      "Epoch 103/120\n",
      "668/668 [==============================] - 0s 252us/sample - loss: 0.2954 - val_loss: 0.2924\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_train[50:], x_train[50:], epochs = 120, validation_data = [x_valid, x_valid], callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in encoder.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    encoder,\n",
    "    keras.layers.Dense(18, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(9, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\my_logs\\run_2020_08_06-12_59_06\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "log_dir = get_run_logdir()\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir)\n",
    "early_stopping_cb2 = keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 172 samples\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDRegularizer object at 0x000001CF8A06DB38>)\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 22ms/sample - loss: 0.7926 - rounded_accuracy: 0.5200 - val_loss: 0.7200 - val_rounded_accuracy: 0.5523\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 977us/sample - loss: 0.7272 - rounded_accuracy: 0.5800 - val_loss: 0.6961 - val_rounded_accuracy: 0.6047\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 818us/sample - loss: 0.6872 - rounded_accuracy: 0.5800 - val_loss: 0.6838 - val_rounded_accuracy: 0.6105\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 719us/sample - loss: 0.6648 - rounded_accuracy: 0.5800 - val_loss: 0.6704 - val_rounded_accuracy: 0.6221\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 937us/sample - loss: 0.6338 - rounded_accuracy: 0.6800 - val_loss: 0.6592 - val_rounded_accuracy: 0.6395\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 661us/sample - loss: 0.6117 - rounded_accuracy: 0.6800 - val_loss: 0.6509 - val_rounded_accuracy: 0.6570\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 639us/sample - loss: 0.6072 - rounded_accuracy: 0.6800 - val_loss: 0.6443 - val_rounded_accuracy: 0.6686\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 778us/sample - loss: 0.6094 - rounded_accuracy: 0.7000 - val_loss: 0.6362 - val_rounded_accuracy: 0.6860\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 718us/sample - loss: 0.5932 - rounded_accuracy: 0.7000 - val_loss: 0.6271 - val_rounded_accuracy: 0.7384\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 638us/sample - loss: 0.5390 - rounded_accuracy: 0.7400 - val_loss: 0.6204 - val_rounded_accuracy: 0.7442\n",
      "Train on 50 samples, validate on 172 samples\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDRegularizer object at 0x000001CF8A06DB38>)\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 24ms/sample - loss: 0.5485 - rounded_accuracy: 0.7200 - val_loss: 0.6107 - val_rounded_accuracy: 0.7209\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 0s 886us/sample - loss: 0.4905 - rounded_accuracy: 0.8200 - val_loss: 0.5967 - val_rounded_accuracy: 0.7267\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 738us/sample - loss: 0.4269 - rounded_accuracy: 0.8400 - val_loss: 0.5911 - val_rounded_accuracy: 0.7151\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 817us/sample - loss: 0.4166 - rounded_accuracy: 0.8200 - val_loss: 0.5883 - val_rounded_accuracy: 0.7093\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 718us/sample - loss: 0.3901 - rounded_accuracy: 0.8600 - val_loss: 0.5888 - val_rounded_accuracy: 0.7151\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 698us/sample - loss: 0.3822 - rounded_accuracy: 0.8400 - val_loss: 0.5904 - val_rounded_accuracy: 0.7151\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 818us/sample - loss: 0.3769 - rounded_accuracy: 0.8200 - val_loss: 0.6010 - val_rounded_accuracy: 0.7093\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 618us/sample - loss: 0.3327 - rounded_accuracy: 0.8400 - val_loss: 0.6036 - val_rounded_accuracy: 0.7151\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 659us/sample - loss: 0.3632 - rounded_accuracy: 0.8600 - val_loss: 0.6008 - val_rounded_accuracy: 0.6977\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 0s 738us/sample - loss: 0.3101 - rounded_accuracy: 0.8600 - val_loss: 0.6019 - val_rounded_accuracy: 0.7093\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 0s 738us/sample - loss: 0.2683 - rounded_accuracy: 0.9400 - val_loss: 0.6048 - val_rounded_accuracy: 0.7093\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True), \n",
    "            metrics=[rounded_accuracy])\n",
    "\n",
    "history = model.fit(x_train[:50], y_train[:50], epochs = 10, validation_data = [x_valid, y_valid], callbacks = [tensorboard_cb])\n",
    "\n",
    "for layer in encoder.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True), \n",
    "            metrics=[rounded_accuracy])\n",
    "\n",
    "history = model.fit(x_train[:50], y_train[:50], epochs = 50, validation_data = [x_valid, y_valid], callbacks = [tensorboard_cb,early_stopping_cb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes([[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6741278872770422, 0.6617647]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = keras.models.Sequential([\n",
    "    keras.layers.Dense(450, activation = 'selu', input_shape=[9]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(300, activation = 'selu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(150, activation = 'selu'),\n",
    "    keras.layers.Dense(20, activation = 'selu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = [rounded_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 718 samples, validate on 172 samples\n",
      "Epoch 1/40\n",
      "718/718 [==============================] - 1s 2ms/sample - loss: 0.6575 - rounded_accuracy: 0.6880 - val_loss: 0.5765 - val_rounded_accuracy: 0.7093\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 0s 186us/sample - loss: 0.6012 - rounded_accuracy: 0.6671 - val_loss: 0.5304 - val_rounded_accuracy: 0.7558\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 0s 175us/sample - loss: 0.5767 - rounded_accuracy: 0.6992 - val_loss: 0.5137 - val_rounded_accuracy: 0.7674\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.5864 - rounded_accuracy: 0.7075 - val_loss: 0.5451 - val_rounded_accuracy: 0.7326\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 0s 182us/sample - loss: 0.5637 - rounded_accuracy: 0.7145 - val_loss: 0.5178 - val_rounded_accuracy: 0.7616\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 0s 183us/sample - loss: 0.5322 - rounded_accuracy: 0.7228 - val_loss: 0.5905 - val_rounded_accuracy: 0.7267\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.5284 - rounded_accuracy: 0.7409 - val_loss: 0.5234 - val_rounded_accuracy: 0.7791\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.5137 - rounded_accuracy: 0.7493 - val_loss: 0.5129 - val_rounded_accuracy: 0.7733\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.5076 - rounded_accuracy: 0.7604 - val_loss: 0.4563 - val_rounded_accuracy: 0.8023\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 0s 170us/sample - loss: 0.4878 - rounded_accuracy: 0.7660 - val_loss: 0.4644 - val_rounded_accuracy: 0.7849\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.4634 - rounded_accuracy: 0.7925 - val_loss: 0.4443 - val_rounded_accuracy: 0.8256\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.4331 - rounded_accuracy: 0.8120 - val_loss: 0.4508 - val_rounded_accuracy: 0.7965\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 0s 176us/sample - loss: 0.4220 - rounded_accuracy: 0.8036 - val_loss: 0.4310 - val_rounded_accuracy: 0.8198\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3929 - rounded_accuracy: 0.8329 - val_loss: 0.3852 - val_rounded_accuracy: 0.8430\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.3777 - rounded_accuracy: 0.8329 - val_loss: 0.3625 - val_rounded_accuracy: 0.8430\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 0s 163us/sample - loss: 0.3526 - rounded_accuracy: 0.8426 - val_loss: 0.3773 - val_rounded_accuracy: 0.8895\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3467 - rounded_accuracy: 0.8663 - val_loss: 0.2995 - val_rounded_accuracy: 0.8953\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 0s 163us/sample - loss: 0.3098 - rounded_accuracy: 0.8760 - val_loss: 0.3227 - val_rounded_accuracy: 0.8663\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.2976 - rounded_accuracy: 0.8872 - val_loss: 0.2980 - val_rounded_accuracy: 0.8953\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3039 - rounded_accuracy: 0.8747 - val_loss: 0.2510 - val_rounded_accuracy: 0.8953\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 0s 178us/sample - loss: 0.2490 - rounded_accuracy: 0.8997 - val_loss: 0.2150 - val_rounded_accuracy: 0.9244\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 0s 178us/sample - loss: 0.2392 - rounded_accuracy: 0.9123 - val_loss: 0.2126 - val_rounded_accuracy: 0.9593\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 0s 171us/sample - loss: 0.2063 - rounded_accuracy: 0.9304 - val_loss: 0.1875 - val_rounded_accuracy: 0.9651\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.1943 - rounded_accuracy: 0.9387 - val_loss: 0.1742 - val_rounded_accuracy: 0.9419\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 0s 171us/sample - loss: 0.1676 - rounded_accuracy: 0.9443 - val_loss: 0.1958 - val_rounded_accuracy: 0.9186\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 0s 152us/sample - loss: 0.1570 - rounded_accuracy: 0.9499 - val_loss: 0.1323 - val_rounded_accuracy: 0.9709\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.1456 - rounded_accuracy: 0.9610 - val_loss: 0.2103 - val_rounded_accuracy: 0.9186\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 0s 177us/sample - loss: 0.1487 - rounded_accuracy: 0.9499 - val_loss: 0.1058 - val_rounded_accuracy: 0.9767\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.1210 - rounded_accuracy: 0.9610 - val_loss: 0.1164 - val_rounded_accuracy: 0.9651\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 0s 182us/sample - loss: 0.1148 - rounded_accuracy: 0.9568 - val_loss: 0.0926 - val_rounded_accuracy: 0.9767\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 0s 179us/sample - loss: 0.1107 - rounded_accuracy: 0.9568 - val_loss: 0.0940 - val_rounded_accuracy: 0.9826\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 0s 167us/sample - loss: 0.0872 - rounded_accuracy: 0.9666 - val_loss: 0.0927 - val_rounded_accuracy: 0.9767\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 0s 167us/sample - loss: 0.0984 - rounded_accuracy: 0.9652 - val_loss: 0.0686 - val_rounded_accuracy: 0.9767\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 0s 166us/sample - loss: 0.1044 - rounded_accuracy: 0.9666 - val_loss: 0.0901 - val_rounded_accuracy: 0.9709\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.0771 - rounded_accuracy: 0.9708 - val_loss: 0.0710 - val_rounded_accuracy: 0.9767\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 0s 166us/sample - loss: 0.0850 - rounded_accuracy: 0.9721 - val_loss: 0.0770 - val_rounded_accuracy: 0.9593\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.0826 - rounded_accuracy: 0.9721 - val_loss: 0.0632 - val_rounded_accuracy: 0.9826\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 0s 161us/sample - loss: 0.0789 - rounded_accuracy: 0.9694 - val_loss: 0.0732 - val_rounded_accuracy: 0.9767\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.0667 - rounded_accuracy: 0.9819 - val_loss: 0.0630 - val_rounded_accuracy: 0.9767\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.0616 - rounded_accuracy: 0.9805 - val_loss: 0.0556 - val_rounded_accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cff6e3c400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset.fit(x_train, y_train, epochs = 40, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021706138614236432, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
