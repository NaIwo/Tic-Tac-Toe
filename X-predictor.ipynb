{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dataset\\data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(PATH):\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    if ext == '.csv':\n",
    "        raw_dataset = pd.read_csv(PATH + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True\n",
       "5  x  x  x  x  o  o  b  b  o   True\n",
       "6  x  x  x  x  o  b  o  o  b   True\n",
       "7  x  x  x  x  o  b  o  b  o   True\n",
       "8  x  x  x  x  o  b  b  o  o   True\n",
       "9  x  x  x  x  b  o  o  o  b   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "raw_dataset.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(dataset):\n",
    "    size = dataset.shape[0]\n",
    "    dataset = dataset[np.random.permutation(size)]\n",
    "    board_x = np.where(dataset[:,:-1] == 'x', 1, np.where(dataset[:,:-1] == 'b', 0, -1))\n",
    "    target_x = np.where(dataset[:,-1:], 1, 0)\n",
    "    return np.concatenate((board_x, target_x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1  0 -1  1  0 -1  1  1  1]\n",
      " [ 0 -1  0  1  1  1 -1  1 -1  1]\n",
      " [ 1 -1 -1  1 -1  1 -1  0  1  0]\n",
      " [-1  1 -1  1  1 -1 -1  1  1  1]\n",
      " [ 0  0 -1  0 -1  1 -1  1  1  0]\n",
      " [ 1  1 -1 -1 -1  0 -1  1  1  0]\n",
      " [ 0 -1  0 -1  0  0  1  1  1  1]\n",
      " [-1  0 -1  1  1  1 -1  1  0  1]\n",
      " [ 1  1 -1 -1  1  0  0  1 -1  1]\n",
      " [ 0  0  1 -1 -1 -1  1  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "dataset = clean(np.array(raw_dataset))\n",
    "print(dataset[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = dataset.shape[0]\n",
    "x_train = (dataset[:size * 75 // 100, :-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_train = dataset[:size * 75 // 100, -1:]\n",
    "x_valid = (dataset[size * 75 // 100:size * 93 // 100, :-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_valid = dataset[size * 75 // 100:size * 93 // 100, -1:]\n",
    "x_test = (dataset[size * 93 // 100:,:-1].astype(np.float32) + 1.0 ) / 2.0\n",
    "y_test = dataset[size * 93 // 100:, -1:]\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(718, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.5 ... 0.  1.  1. ]\n",
      " [0.5 0.  0.5 ... 0.  1.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.5 1. ]\n",
      " ...\n",
      " [0.  0.5 1.  ... 1.  0.  0. ]\n",
      " [1.  0.  0.  ... 0.  1.  1. ]\n",
      " [0.  0.  0.  ... 1.  0.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "kl_divergence = keras.losses.kullback_leibler_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, weight, target = 0.1):\n",
    "        self.weight = weight\n",
    "        self.target = target\n",
    "    def  __call__(self, inputs):\n",
    "        mean_activities = K.mean(inputs, axis = 0)\n",
    "        return self.weight * (\n",
    "             kl_divergence(self.target, mean_activities) +\n",
    "             kl_divergence(1. - self.target, 1. - mean_activities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_reg = KLDRegularizer(weight = 0.05, target = 0.1)\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(450, activation = 'elu', input_shape = [9], kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(300, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(150, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(36, activation = 'sigmoid',activity_regularizer=kld_reg, kernel_initializer = 'he_normal')\n",
    "    #keras.layers.ActivityRegularization(l1=1e-3)\n",
    "])\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.Dense(150, activation = 'elu', input_shape = [36],  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(300, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(450, activation = 'elu',  kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(9, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "autoencoder = keras.models.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_23 (Sequential)   (None, 36)                190386    \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (None, 9)                 190359    \n",
      "=================================================================\n",
      "Total params: 380,745\n",
      "Trainable params: 380,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', \n",
    "                    optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.92, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 172 samples\n",
      "Epoch 1/120\n",
      "668/668 [==============================] - 1s 2ms/sample - loss: 0.3721 - val_loss: 0.3348\n",
      "Epoch 2/120\n",
      "668/668 [==============================] - 0s 205us/sample - loss: 0.3182 - val_loss: 0.3197\n",
      "Epoch 3/120\n",
      "668/668 [==============================] - 0s 173us/sample - loss: 0.3111 - val_loss: 0.3105\n",
      "Epoch 4/120\n",
      "668/668 [==============================] - 0s 175us/sample - loss: 0.3066 - val_loss: 0.3106\n",
      "Epoch 5/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.3049 - val_loss: 0.3046\n",
      "Epoch 6/120\n",
      "668/668 [==============================] - 0s 166us/sample - loss: 0.3006 - val_loss: 0.3039\n",
      "Epoch 7/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.3016 - val_loss: 0.3034\n",
      "Epoch 8/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.2986 - val_loss: 0.3022\n",
      "Epoch 9/120\n",
      "668/668 [==============================] - 0s 169us/sample - loss: 0.2974 - val_loss: 0.3006\n",
      "Epoch 10/120\n",
      "668/668 [==============================] - 0s 167us/sample - loss: 0.2974 - val_loss: 0.2981\n",
      "Epoch 11/120\n",
      "668/668 [==============================] - 0s 172us/sample - loss: 0.2966 - val_loss: 0.3025\n",
      "Epoch 12/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2953 - val_loss: 0.2998\n",
      "Epoch 13/120\n",
      "668/668 [==============================] - 0s 167us/sample - loss: 0.2955 - val_loss: 0.2987\n",
      "Epoch 14/120\n",
      "668/668 [==============================] - 0s 169us/sample - loss: 0.2948 - val_loss: 0.2973\n",
      "Epoch 15/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2941 - val_loss: 0.3000\n",
      "Epoch 16/120\n",
      "668/668 [==============================] - 0s 160us/sample - loss: 0.2937 - val_loss: 0.2957\n",
      "Epoch 17/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2931 - val_loss: 0.2965\n",
      "Epoch 18/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.2935 - val_loss: 0.2949\n",
      "Epoch 19/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2928 - val_loss: 0.2970\n",
      "Epoch 20/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2923 - val_loss: 0.2954\n",
      "Epoch 21/120\n",
      "668/668 [==============================] - 0s 172us/sample - loss: 0.2924 - val_loss: 0.2957\n",
      "Epoch 22/120\n",
      "668/668 [==============================] - 0s 167us/sample - loss: 0.2920 - val_loss: 0.2941\n",
      "Epoch 23/120\n",
      "668/668 [==============================] - 0s 169us/sample - loss: 0.2914 - val_loss: 0.2962\n",
      "Epoch 24/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2919 - val_loss: 0.2954\n",
      "Epoch 25/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2917 - val_loss: 0.2942\n",
      "Epoch 26/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2913 - val_loss: 0.2938\n",
      "Epoch 27/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2911 - val_loss: 0.2953\n",
      "Epoch 28/120\n",
      "668/668 [==============================] - 0s 179us/sample - loss: 0.2911 - val_loss: 0.2931\n",
      "Epoch 29/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2911 - val_loss: 0.2934\n",
      "Epoch 30/120\n",
      "668/668 [==============================] - 0s 167us/sample - loss: 0.2905 - val_loss: 0.2935\n",
      "Epoch 31/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2907 - val_loss: 0.2932\n",
      "Epoch 32/120\n",
      "668/668 [==============================] - 0s 172us/sample - loss: 0.2907 - val_loss: 0.2927\n",
      "Epoch 33/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2908 - val_loss: 0.2951\n",
      "Epoch 34/120\n",
      "668/668 [==============================] - 0s 169us/sample - loss: 0.2905 - val_loss: 0.2931\n",
      "Epoch 35/120\n",
      "668/668 [==============================] - 0s 160us/sample - loss: 0.2903 - val_loss: 0.2940\n",
      "Epoch 36/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2901 - val_loss: 0.2940\n",
      "Epoch 37/120\n",
      "668/668 [==============================] - 0s 173us/sample - loss: 0.2904 - val_loss: 0.2926\n",
      "Epoch 38/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2899 - val_loss: 0.2932\n",
      "Epoch 39/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2902 - val_loss: 0.2937\n",
      "Epoch 40/120\n",
      "668/668 [==============================] - 0s 172us/sample - loss: 0.2901 - val_loss: 0.2933\n",
      "Epoch 41/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2899 - val_loss: 0.2937\n",
      "Epoch 42/120\n",
      "668/668 [==============================] - 0s 169us/sample - loss: 0.2901 - val_loss: 0.2933\n",
      "Epoch 43/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2896 - val_loss: 0.2940\n",
      "Epoch 44/120\n",
      "668/668 [==============================] - 0s 161us/sample - loss: 0.2899 - val_loss: 0.2927\n",
      "Epoch 45/120\n",
      "668/668 [==============================] - 0s 166us/sample - loss: 0.2897 - val_loss: 0.2926\n",
      "Epoch 46/120\n",
      "668/668 [==============================] - 0s 166us/sample - loss: 0.2897 - val_loss: 0.2923\n",
      "Epoch 47/120\n",
      "668/668 [==============================] - 0s 173us/sample - loss: 0.2897 - val_loss: 0.2927\n",
      "Epoch 48/120\n",
      "668/668 [==============================] - 0s 158us/sample - loss: 0.2894 - val_loss: 0.2928\n",
      "Epoch 49/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.2897 - val_loss: 0.2918\n",
      "Epoch 50/120\n",
      "668/668 [==============================] - 0s 167us/sample - loss: 0.2894 - val_loss: 0.2929\n",
      "Epoch 51/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2898 - val_loss: 0.2931\n",
      "Epoch 52/120\n",
      "668/668 [==============================] - 0s 166us/sample - loss: 0.2891 - val_loss: 0.2925\n",
      "Epoch 53/120\n",
      "668/668 [==============================] - 0s 157us/sample - loss: 0.2895 - val_loss: 0.2922\n",
      "Epoch 54/120\n",
      "668/668 [==============================] - 0s 170us/sample - loss: 0.2893 - val_loss: 0.2933\n",
      "Epoch 55/120\n",
      "668/668 [==============================] - 0s 164us/sample - loss: 0.2894 - val_loss: 0.2925\n",
      "Epoch 56/120\n",
      "668/668 [==============================] - 0s 163us/sample - loss: 0.2893 - val_loss: 0.2928\n",
      "Epoch 57/120\n",
      "668/668 [==============================] - 0s 166us/sample - loss: 0.2893 - val_loss: 0.2921\n",
      "Epoch 58/120\n",
      "668/668 [==============================] - 0s 160us/sample - loss: 0.2893 - val_loss: 0.2925\n",
      "Epoch 59/120\n",
      "668/668 [==============================] - 0s 172us/sample - loss: 0.2893 - val_loss: 0.2931\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_train[50:], x_train[50:], epochs = 120, validation_data = [x_valid, x_valid], callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in encoder.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    encoder,\n",
    "    keras.layers.Dense(18, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(9, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\my_logs\\run_2020_08_06-13_23_49\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "log_dir = get_run_logdir()\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir)\n",
    "early_stopping_cb2 = keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 172 samples\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDRegularizer object at 0x000002A3D65F3940>)\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 1s 20ms/sample - loss: 0.6566 - rounded_accuracy: 0.5600 - val_loss: 0.6312 - val_rounded_accuracy: 0.6628\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 852us/sample - loss: 0.5695 - rounded_accuracy: 0.7400 - val_loss: 0.6149 - val_rounded_accuracy: 0.6744\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 578us/sample - loss: 0.5162 - rounded_accuracy: 0.7600 - val_loss: 0.6097 - val_rounded_accuracy: 0.6977\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 679us/sample - loss: 0.5137 - rounded_accuracy: 0.7400 - val_loss: 0.6129 - val_rounded_accuracy: 0.6860\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 579us/sample - loss: 0.4652 - rounded_accuracy: 0.8400 - val_loss: 0.6102 - val_rounded_accuracy: 0.6919\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 539us/sample - loss: 0.4483 - rounded_accuracy: 0.8800 - val_loss: 0.6163 - val_rounded_accuracy: 0.6860\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 618us/sample - loss: 0.4265 - rounded_accuracy: 0.8800 - val_loss: 0.6177 - val_rounded_accuracy: 0.6919\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 558us/sample - loss: 0.4064 - rounded_accuracy: 0.9000 - val_loss: 0.6192 - val_rounded_accuracy: 0.6977\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 618us/sample - loss: 0.3930 - rounded_accuracy: 0.8600 - val_loss: 0.6196 - val_rounded_accuracy: 0.6977\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 558us/sample - loss: 0.3739 - rounded_accuracy: 0.8800 - val_loss: 0.6189 - val_rounded_accuracy: 0.7093\n",
      "Train on 50 samples, validate on 172 samples\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', <__main__.KLDRegularizer object at 0x000002A3D65F3940>)\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 1s 22ms/sample - loss: 0.4122 - rounded_accuracy: 0.7800 - val_loss: 0.7002 - val_rounded_accuracy: 0.6628\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2943 - rounded_accuracy: 0.93 - 0s 697us/sample - loss: 0.2800 - rounded_accuracy: 0.9000 - val_loss: 0.6061 - val_rounded_accuracy: 0.7558\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 0s 598us/sample - loss: 0.1906 - rounded_accuracy: 0.9800 - val_loss: 0.6604 - val_rounded_accuracy: 0.7384\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 0s 639us/sample - loss: 0.1523 - rounded_accuracy: 1.0000 - val_loss: 0.6601 - val_rounded_accuracy: 0.7558\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 0s 599us/sample - loss: 0.1203 - rounded_accuracy: 1.0000 - val_loss: 0.6658 - val_rounded_accuracy: 0.7674\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 0s 639us/sample - loss: 0.1011 - rounded_accuracy: 1.0000 - val_loss: 0.6948 - val_rounded_accuracy: 0.7674\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 0s 525us/sample - loss: 0.0803 - rounded_accuracy: 1.0000 - val_loss: 0.7119 - val_rounded_accuracy: 0.7674\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 0s 813us/sample - loss: 0.0698 - rounded_accuracy: 1.0000 - val_loss: 0.7279 - val_rounded_accuracy: 0.7674\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 0s 501us/sample - loss: 0.0614 - rounded_accuracy: 1.0000 - val_loss: 0.7574 - val_rounded_accuracy: 0.7616\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True), \n",
    "            metrics=[rounded_accuracy])\n",
    "\n",
    "history = model.fit(x_train[:50], y_train[:50], epochs = 10, validation_data = [x_valid, y_valid], callbacks = [tensorboard_cb])\n",
    "\n",
    "for layer in encoder.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizers =  keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True), \n",
    "            metrics=[rounded_accuracy])\n",
    "\n",
    "history = model.fit(x_train[:50], y_train[:50], epochs = 50, validation_data = [x_valid, y_valid], callbacks = [tensorboard_cb,early_stopping_cb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes([[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7177933156490326, 0.7352941]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset = keras.models.Sequential([\n",
    "    keras.layers.Dense(450, activation = 'selu', input_shape=[9]),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(300, activation = 'selu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(150, activation = 'selu'),\n",
    "    keras.layers.Dense(20, activation = 'selu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dataset.compile(loss='binary_crossentropy', optimizer = 'nadam', metrics = [rounded_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 718 samples, validate on 172 samples\n",
      "Epoch 1/40\n",
      "718/718 [==============================] - 1s 2ms/sample - loss: 0.6575 - rounded_accuracy: 0.6880 - val_loss: 0.5765 - val_rounded_accuracy: 0.7093\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 0s 186us/sample - loss: 0.6012 - rounded_accuracy: 0.6671 - val_loss: 0.5304 - val_rounded_accuracy: 0.7558\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 0s 175us/sample - loss: 0.5767 - rounded_accuracy: 0.6992 - val_loss: 0.5137 - val_rounded_accuracy: 0.7674\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.5864 - rounded_accuracy: 0.7075 - val_loss: 0.5451 - val_rounded_accuracy: 0.7326\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 0s 182us/sample - loss: 0.5637 - rounded_accuracy: 0.7145 - val_loss: 0.5178 - val_rounded_accuracy: 0.7616\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 0s 183us/sample - loss: 0.5322 - rounded_accuracy: 0.7228 - val_loss: 0.5905 - val_rounded_accuracy: 0.7267\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.5284 - rounded_accuracy: 0.7409 - val_loss: 0.5234 - val_rounded_accuracy: 0.7791\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.5137 - rounded_accuracy: 0.7493 - val_loss: 0.5129 - val_rounded_accuracy: 0.7733\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.5076 - rounded_accuracy: 0.7604 - val_loss: 0.4563 - val_rounded_accuracy: 0.8023\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 0s 170us/sample - loss: 0.4878 - rounded_accuracy: 0.7660 - val_loss: 0.4644 - val_rounded_accuracy: 0.7849\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.4634 - rounded_accuracy: 0.7925 - val_loss: 0.4443 - val_rounded_accuracy: 0.8256\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.4331 - rounded_accuracy: 0.8120 - val_loss: 0.4508 - val_rounded_accuracy: 0.7965\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 0s 176us/sample - loss: 0.4220 - rounded_accuracy: 0.8036 - val_loss: 0.4310 - val_rounded_accuracy: 0.8198\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3929 - rounded_accuracy: 0.8329 - val_loss: 0.3852 - val_rounded_accuracy: 0.8430\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.3777 - rounded_accuracy: 0.8329 - val_loss: 0.3625 - val_rounded_accuracy: 0.8430\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 0s 163us/sample - loss: 0.3526 - rounded_accuracy: 0.8426 - val_loss: 0.3773 - val_rounded_accuracy: 0.8895\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3467 - rounded_accuracy: 0.8663 - val_loss: 0.2995 - val_rounded_accuracy: 0.8953\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 0s 163us/sample - loss: 0.3098 - rounded_accuracy: 0.8760 - val_loss: 0.3227 - val_rounded_accuracy: 0.8663\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 0s 174us/sample - loss: 0.2976 - rounded_accuracy: 0.8872 - val_loss: 0.2980 - val_rounded_accuracy: 0.8953\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.3039 - rounded_accuracy: 0.8747 - val_loss: 0.2510 - val_rounded_accuracy: 0.8953\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 0s 178us/sample - loss: 0.2490 - rounded_accuracy: 0.8997 - val_loss: 0.2150 - val_rounded_accuracy: 0.9244\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 0s 178us/sample - loss: 0.2392 - rounded_accuracy: 0.9123 - val_loss: 0.2126 - val_rounded_accuracy: 0.9593\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 0s 171us/sample - loss: 0.2063 - rounded_accuracy: 0.9304 - val_loss: 0.1875 - val_rounded_accuracy: 0.9651\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.1943 - rounded_accuracy: 0.9387 - val_loss: 0.1742 - val_rounded_accuracy: 0.9419\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 0s 171us/sample - loss: 0.1676 - rounded_accuracy: 0.9443 - val_loss: 0.1958 - val_rounded_accuracy: 0.9186\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 0s 152us/sample - loss: 0.1570 - rounded_accuracy: 0.9499 - val_loss: 0.1323 - val_rounded_accuracy: 0.9709\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.1456 - rounded_accuracy: 0.9610 - val_loss: 0.2103 - val_rounded_accuracy: 0.9186\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 0s 177us/sample - loss: 0.1487 - rounded_accuracy: 0.9499 - val_loss: 0.1058 - val_rounded_accuracy: 0.9767\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.1210 - rounded_accuracy: 0.9610 - val_loss: 0.1164 - val_rounded_accuracy: 0.9651\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 0s 182us/sample - loss: 0.1148 - rounded_accuracy: 0.9568 - val_loss: 0.0926 - val_rounded_accuracy: 0.9767\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 0s 179us/sample - loss: 0.1107 - rounded_accuracy: 0.9568 - val_loss: 0.0940 - val_rounded_accuracy: 0.9826\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 0s 167us/sample - loss: 0.0872 - rounded_accuracy: 0.9666 - val_loss: 0.0927 - val_rounded_accuracy: 0.9767\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 0s 167us/sample - loss: 0.0984 - rounded_accuracy: 0.9652 - val_loss: 0.0686 - val_rounded_accuracy: 0.9767\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 0s 166us/sample - loss: 0.1044 - rounded_accuracy: 0.9666 - val_loss: 0.0901 - val_rounded_accuracy: 0.9709\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 0s 165us/sample - loss: 0.0771 - rounded_accuracy: 0.9708 - val_loss: 0.0710 - val_rounded_accuracy: 0.9767\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 0s 166us/sample - loss: 0.0850 - rounded_accuracy: 0.9721 - val_loss: 0.0770 - val_rounded_accuracy: 0.9593\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 0s 168us/sample - loss: 0.0826 - rounded_accuracy: 0.9721 - val_loss: 0.0632 - val_rounded_accuracy: 0.9826\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 0s 161us/sample - loss: 0.0789 - rounded_accuracy: 0.9694 - val_loss: 0.0732 - val_rounded_accuracy: 0.9767\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 0s 169us/sample - loss: 0.0667 - rounded_accuracy: 0.9819 - val_loss: 0.0630 - val_rounded_accuracy: 0.9767\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 0s 172us/sample - loss: 0.0616 - rounded_accuracy: 0.9805 - val_loss: 0.0556 - val_rounded_accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cff6e3c400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset.fit(x_train, y_train, epochs = 40, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021706138614236432, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_dataset.evaluate(x_test, y_test, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
